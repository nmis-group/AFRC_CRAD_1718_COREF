{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visuals import *\n",
    "from utils import *\n",
    "from model import *\n",
    "from dataset import *\n",
    "from data_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (14,10)\n",
    "font = {'family' : 'DejaVu Sans',  'weight' : 'normal',  'size'  : 22}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_strat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bboxes\"] = df[\"bboxes\"].apply(eval) # DONT forget this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm = BoltDataModule(df, num_workers = 16, bs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tf_efficientnetv2_l', 'backbone_name': 'tf_efficientnetv2_l', 'backbone_args': {'drop_path_rate': 0.2}, 'backbone_indices': None, 'image_size': [1024, 1024], 'num_classes': 1, 'min_level': 3, 'max_level': 7, 'num_levels': 5, 'num_scales': 3, 'aspect_ratios': [[1.0, 1.0], [1.4, 0.7], [0.7, 1.4]], 'anchor_scale': 4.0, 'pad_type': 'same', 'act_type': 'swish', 'norm_layer': None, 'norm_kwargs': {'eps': 0.001, 'momentum': 0.01}, 'box_class_repeats': 3, 'fpn_cell_repeats': 3, 'fpn_channels': 88, 'separable_conv': True, 'apply_resample_bn': True, 'conv_after_downsample': False, 'conv_bn_relu_pattern': False, 'use_native_resize_op': False, 'downsample_type': 'max', 'upsample_type': 'nearest', 'redundant_bias': True, 'head_bn_level_first': False, 'head_act_type': None, 'fpn_name': None, 'fpn_config': None, 'fpn_drop_path_rate': 0.0, 'alpha': 0.25, 'gamma': 1.5, 'label_smoothing': 0.0, 'legacy_focal': False, 'jit_loss': False, 'delta': 0.1, 'box_loss_weight': 50.0, 'soft_nms': False, 'max_detection_points': 5000, 'max_det_per_image': 100, 'url': ''}\n",
      "backbone True\n",
      "fpn True\n",
      "class_net True\n",
      "box_net True\n",
      "65\n",
      "21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "model = BoltDetector(df, bs=3, num_classes=1, img_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/hdd/astamoulakatos/NMIS/detector/detector-epoch=98-valid_loss=0.12.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tf_efficientnetv2_l', 'backbone_name': 'tf_efficientnetv2_l', 'backbone_args': {'drop_path_rate': 0.2}, 'backbone_indices': None, 'image_size': [1024, 1024], 'num_classes': 1, 'min_level': 3, 'max_level': 7, 'num_levels': 5, 'num_scales': 3, 'aspect_ratios': [[1.0, 1.0], [1.4, 0.7], [0.7, 1.4]], 'anchor_scale': 4.0, 'pad_type': 'same', 'act_type': 'swish', 'norm_layer': None, 'norm_kwargs': {'eps': 0.001, 'momentum': 0.01}, 'box_class_repeats': 3, 'fpn_cell_repeats': 3, 'fpn_channels': 88, 'separable_conv': True, 'apply_resample_bn': True, 'conv_after_downsample': False, 'conv_bn_relu_pattern': False, 'use_native_resize_op': False, 'downsample_type': 'max', 'upsample_type': 'nearest', 'redundant_bias': True, 'head_bn_level_first': False, 'head_act_type': None, 'fpn_name': None, 'fpn_config': None, 'fpn_drop_path_rate': 0.0, 'alpha': 0.25, 'gamma': 1.5, 'label_smoothing': 0.0, 'legacy_focal': False, 'jit_loss': False, 'delta': 0.1, 'box_loss_weight': 50.0, 'soft_nms': False, 'max_detection_points': 5000, 'max_det_per_image': 100, 'url': ''}\n",
      "backbone True\n",
      "fpn True\n",
      "class_net True\n",
      "box_net True\n",
      "65\n",
      "21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "model = model.load_from_checkpoint(path, map_location='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = model.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/astamoulakatos/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/astamoulakatos/.local/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for batch in loader:\n",
    "    output = model.validation_step(batch=batch, batch_idx=0)\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.766\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.965\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.766\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': tensor(0.1277),\n",
       " 'metrics': {'AP_all': 0.7661014823847874,\n",
       "  'AP_all_IOU_0_50': 1.0,\n",
       "  'AP_all_IOU_0_75': 0.9652679553669653,\n",
       "  'AP_small': -1.0,\n",
       "  'AP_medium': 0.7661014823847874,\n",
       "  'AP_large': -1.0,\n",
       "  'AR_all_dets_1': 0.014285714285714285,\n",
       "  'AR_all_dets_10': 0.1222222222222222,\n",
       "  'AR_all': 0.8158730158730159,\n",
       "  'AR_small': -1.0,\n",
       "  'AR_medium': 0.8158730158730159,\n",
       "  'AR_large': -1.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = model.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for batch in loader:\n",
    "    output = model.validation_step(batch=batch, batch_idx=0)\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.720\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.972\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.897\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.720\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.788\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.788\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': tensor(0.1385),\n",
       " 'metrics': {'AP_all': 0.7201017233726746,\n",
       "  'AP_all_IOU_0_50': 0.9715156130997715,\n",
       "  'AP_all_IOU_0_75': 0.8967901998533188,\n",
       "  'AP_small': -1.0,\n",
       "  'AP_medium': 0.7201017233726746,\n",
       "  'AP_large': -1.0,\n",
       "  'AR_all_dets_1': 0.013846153846153847,\n",
       "  'AR_all_dets_10': 0.12153846153846155,\n",
       "  'AR_all': 0.7876923076923077,\n",
       "  'AR_small': -1.0,\n",
       "  'AR_medium': 0.7876923076923077,\n",
       "  'AR_large': -1.0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': tensor([[[8.6121e+01, 1.1004e+02, 1.3687e+02, 1.7759e+02, 8.7688e-01,\n",
       "           1.0000e+00],\n",
       "          [9.6167e+01, 1.3312e+02, 1.3550e+02, 1.7552e+02, 5.1463e-02,\n",
       "           1.0000e+00],\n",
       "          [8.7745e+01, 1.4154e+02, 1.2732e+02, 1.8299e+02, 4.0714e-02,\n",
       "           1.0000e+00],\n",
       "          ...,\n",
       "          [2.9413e+02, 6.6614e+02, 3.6544e+02, 7.9670e+02, 1.3971e-02,\n",
       "           1.0000e+00],\n",
       "          [9.7429e+02, 9.9286e+02, 9.9704e+02, 1.0240e+03, 1.3951e-02,\n",
       "           1.0000e+00],\n",
       "          [1.0776e+02, 0.0000e+00, 1.5770e+02, 6.4240e+01, 1.3939e-02,\n",
       "           1.0000e+00]],\n",
       " \n",
       "         [[1.1864e+02, 1.5935e+02, 1.6928e+02, 2.2681e+02, 8.7770e-01,\n",
       "           1.0000e+00],\n",
       "          [1.3201e+02, 1.6639e+02, 1.8291e+02, 2.3320e+02, 7.0212e-02,\n",
       "           1.0000e+00],\n",
       "          [1.2841e+02, 1.8128e+02, 1.6774e+02, 2.2421e+02, 6.6100e-02,\n",
       "           1.0000e+00],\n",
       "          ...,\n",
       "          [9.4291e+02, 1.8058e+02, 1.0240e+03, 3.3042e+02, 1.3731e-02,\n",
       "           1.0000e+00],\n",
       "          [0.0000e+00, 2.6586e+02, 4.2329e+01, 3.8352e+02, 1.3712e-02,\n",
       "           1.0000e+00],\n",
       "          [0.0000e+00, 7.4162e+01, 4.2454e+01, 1.9305e+02, 1.3695e-02,\n",
       "           1.0000e+00]]]),\n",
       " 'targets': [{'bboxes': tensor([[109.7143,  85.3333, 177.4391, 136.1270]]),\n",
       "   'labels': tensor([1]),\n",
       "   'bolts': 1,\n",
       "   'img_size': [1024, 1024],\n",
       "   'img_scale': tensor([1.])},\n",
       "  {'bboxes': tensor([[158.8148, 118.3492, 224.5079, 170.4127]]),\n",
       "   'labels': tensor([1]),\n",
       "   'bolts': 1,\n",
       "   'img_size': [1024, 1024],\n",
       "   'img_scale': tensor([1.])}],\n",
       " 'bolts_counted': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['batch_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
