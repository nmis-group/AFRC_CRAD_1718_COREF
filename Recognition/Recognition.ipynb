{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognition with OpenCV haar cascade classifier\n",
    "\n",
    "The following code works with opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-33a710bb778a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# but we want it as RGB We'll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# also need a grayscale version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mimg_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mimg_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#Sample code for image recognition with OpenCV\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Opening image\n",
    "img = cv2.imread(\"Images\\2021-10-21_01_bitzblock_0005.jpg\")\n",
    "# OpenCV opens images as BRG\n",
    "# but we want it as RGB We'll\n",
    "# also need a grayscale version\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Use minSize because for not\n",
    "# bothering with extra-small\n",
    "# dots that would look like STOP signs\n",
    "stop_data = cv2.CascadeClassifier('cascade.xml')\n",
    "\n",
    "found = stop_data.detectMultiScale(img_gray, minSize =(20, 20))\n",
    "\n",
    "# Don't do anything if there's\n",
    "# no sign\n",
    "amount_found = len(found)\n",
    "\n",
    "if amount_found != 0:\n",
    "    # There may be more than one\n",
    "    # sign in the image\n",
    "    for (x, y, width, height) in found:\n",
    "        # We draw a green rectangle around\n",
    "        # every recognized sign\n",
    "        cv2.rectangle(img_rgb, (x, y),\n",
    "                     (x + height, y + width),\n",
    "                     (0, 255, 0), 5)\n",
    "\n",
    "# Creates the environment of\n",
    "# the picture and shows it\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1625e2ca46e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## following is an test image u can take any image from the p folder in the temp folder and paste address of it on below line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Images\\2021-10-21_01_bitzblock_0005.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m###path of image file which we want to detect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mresized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#try to tune this 6.5 and 17 parameter to get good result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4-dev) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "#here is code to check the output\n",
    "import cv2\n",
    "face_cascade=cv2.CascadeClassifier(\"cascade.xml\")###path of cascade file\n",
    "## following is an test image u can take any image from the p folder in the temp folder and paste address of it on below line \n",
    "img= cv2.imread(\"Images\\2021-10-21_01_bitzblock_0005.jpg\")###path of image file which we want to detect\n",
    "resized = cv2.resize(img,(400,400),interpolation=cv2.INTER_CUBIC)\n",
    "gray=cv2.cvtColor(resized,cv2.COLOR_BGR2GRAY)\n",
    "faces=face_cascade.detectMultiScale(gray,6.5,17)#try to tune this 6.5 and 17 parameter to get good result \n",
    "##if not getting good result try to train new cascade.xml file again deleting other file expect p and n in temp folder\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    resized=cv2.rectangle(resized,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('img',resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN method\n",
    "The following code is reference from:\n",
    "https://medium.com/analytics-vidhya/object-detection-with-opencv-step-by-step-6c49a9cc1ff0\n",
    "\n",
    "Object detection with the CNN model \n",
    "\n",
    "Requirement:\n",
    "opencv-contrib-python\n",
    "\n",
    "If you have installed opencv-python try the following command:\n",
    "\n",
    "```sh\n",
    "pip uninstall opencv-python\n",
    "\n",
    "pip install opencv-contrib-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "# For measuring the inference time.\n",
    "import time\n",
    "import random\n",
    "# Computer Vision\n",
    "import cv2\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Math\n",
    "import numpy as np\n",
    "# File handling\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "classes = [\"box\", \"block\", \"bolt\"]\n",
    "\n",
    "def display_image(image_num):\n",
    "    \"\"\"\n",
    "    Prints out picture of\n",
    "    the image that is selected\n",
    "    \n",
    "    After the else statement,\n",
    "    we try to use the file name\n",
    "    in oder to print out the image,\n",
    "    \n",
    "    while the first image is used to \n",
    "    print the image directly without a \n",
    "    filename.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[image_num])\n",
    "    except (RuntimeError, TypeError, NameError):\n",
    "        print(\"[INFO] Could not print image\")\n",
    "        print(\"[INFO] trying something else...\")\n",
    "    else:\n",
    "        print(\"[INFO] returning image...\")\n",
    "        # Image path - getting images on file\n",
    "        image_paths = \"Images/\"\n",
    "        image_select = image_paths + ([f for f in listdir(image_paths) if isfile(join(image_paths, f))][image_num])  # Other way instead of the listdir function\n",
    "        img = plt.imread(fname=image_select)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "# Prediction Function\n",
    "def predict(model, image_num):\n",
    "    # Image path - getting images on file\n",
    "    image_paths = \"Images/\"\n",
    "    image_select = image_paths + ([f for f in listdir(image_paths) if isfile(join(image_paths, f))])[image_num] # Other way instead of the listdir function\n",
    "    \n",
    "    img = load_img(image_select, target_size=(300, 300))  # Loading image\n",
    "    img = img_to_array(img)  # Transforming image to array\n",
    "    img = img / 255  # Normalizing Image\n",
    "    img = np.expand_dims(img, axis=0)  # Expanding dimensions\n",
    "    predict = cnn_model.predict(img)  # Predicting the image\n",
    "    pred_name = classes[np.argmax(predict)]  # Predicting the name\n",
    "    prediction = str(round(predict.max() * 100, 3))\n",
    "    print(display_image(image_num=image_num))\n",
    "    return prediction + '%', pred_name\n",
    "\n",
    "# Prediction Function\n",
    "def predict_region_of_interest(model, proposals_used):\n",
    "    \"\"\"\n",
    "    predicts region proposals\n",
    "    \"\"\"\n",
    "    predict = model.predict(proposals_used)  # Predicting the image\n",
    "    for proposals in predict:\n",
    "        pred_name = classes[np.argmax(proposals)]  # Predicting the name\n",
    "    prediction = str(round(predict.max() * 100, 3))\n",
    "    print(pred_name)\n",
    "    return predict\n",
    "\n",
    "def compute_iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    IOU is a form of \n",
    "    performance measurement\n",
    "    for our object detector.\n",
    "    \"\"\"\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "#  Felzenszwalb et al.\n",
    "def non_max_suppression(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list, add the index\n",
    "        # value to the list of picked indexes, then initialize\n",
    "        # the suppression list (i.e. indexes that will be deleted)\n",
    "        # using the last index\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        suppress = [last]\n",
    "        # loop over all indexes in the indexes list\n",
    "        for pos in range(0, last):\n",
    "            # grab the current index\n",
    "            j = idxs[pos]\n",
    "            # find the largest (x, y) coordinates for the start of\n",
    "            # the bounding box and the smallest (x, y) coordinates\n",
    "            # for the end of the bounding box\n",
    "            xx1 = max(x1[i], x1[j])\n",
    "            yy1 = max(y1[i], y1[j])\n",
    "            xx2 = min(x2[i], x2[j])\n",
    "            yy2 = min(y2[i], y2[j])\n",
    "            # compute the width and height of the bounding box\n",
    "            w = max(0, xx2 - xx1 + 1)\n",
    "            h = max(0, yy2 - yy1 + 1)\n",
    "            # compute the ratio of overlap between the computed\n",
    "            # bounding box and the bounding box in the area list\n",
    "            overlap = float(w * h) / area[j]\n",
    "            # if there is sufficient overlap, suppress the\n",
    "            # current bounding box\n",
    "            if overlap > overlapThresh:\n",
    "                suppress.append(pos)\n",
    "        # delete all indexes from the index list that are in the\n",
    "        # suppression list\n",
    "        idxs = np.delete(idxs, suppress)\n",
    "    # return only the bounding boxes that were picked\n",
    "    return boxes[pick]\n",
    "\n",
    "# Setting a max amount of region proposals used when running selective search\n",
    "max_proposals = 2000\n",
    "max_proposals_infer = 100  # Search for (1) gathering training data and (2) performing inference\n",
    "\n",
    "# initialize the input dimensions to the network\n",
    "input_dimensions = (300, 300)  # 300 by 300 because that's what the CNN Model was tested on\n",
    "# define the path to the output model\n",
    "model_path = \"model_3.hdf5\"\n",
    "cnn_model = keras.models.load_model(model_path)  # Loading CNN model from keras\n",
    "# define the minimum probability required for a positive prediction\n",
    "# (used to filter out false-positive predictions)\n",
    "min_probability = 0.90\n",
    "\n",
    "# initialize OpenCV's selective search implementation and set the\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "# Input image in selective search\n",
    "# Image path - getting images on file\n",
    "image_num = 19\n",
    "image_paths = \"Images/\"\n",
    "image_select = image_paths + ([f for f in listdir(image_paths) if isfile(join(image_paths, f))][image_num])  # Other way instead of the listdir function\n",
    "# Making image compatible with imshow\n",
    "image = cv2.imread(image_select)\n",
    "# load the input image (300x300) and preprocess it\n",
    "image = cv2.resize(image, input_dimensions)  # Increasing image means more regions\n",
    "# Setting base image that will be used\n",
    "ss.setBaseImage(image)\n",
    "# Choosing which selective search\n",
    "ss.switchToSelectiveSearchQuality()\n",
    "\n",
    "# run selective search on the input image\n",
    "start = time.time()\n",
    "rects = ss.process()  # Run Selective Search\n",
    "end = time.time()\n",
    "# show how along selective search took to run along with the total\n",
    "# number of returned region proposals\n",
    "print(f\"[INFO] selective search took {np.round(end - start, decimals=3)} seconds\")\n",
    "print(f\"[INFO] {len(rects)} total region proposals\")\n",
    "\n",
    "# initialize the list of region proposals that we'll be classifying\n",
    "# along with their associated bounding boxes\n",
    "proposals = []\n",
    "boxes = []\n",
    "# loop over the region proposal bounding box coordinates generated by\n",
    "# running selective search\n",
    "for (x, y, w, h) in rects[:max_proposals_infer]:\n",
    "    # extract the region from the input image, convert it from BGR to\n",
    "    # RGB channel ordering, and then resize it to the required input\n",
    "    # dimensions of our trained CNN\n",
    "    roi = image[y:y + h, x:x + w]\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    roi = cv2.resize(roi, input_dimensions,\n",
    "        interpolation=cv2.INTER_CUBIC)\n",
    "    # further preprocess the ROI\n",
    "    roi = img_to_array(roi)\n",
    "    roi = preprocess_input(roi)\n",
    "    # update our proposals and bounding boxes lists\n",
    "    proposals.append(roi)\n",
    "    boxes.append((x, y, x + w, y + h))\n",
    "    \n",
    "# convert the proposals and bounding boxes into NumPy arrays\n",
    "proposals = np.array(proposals, dtype=\"float64\")\n",
    "boxes = np.array(boxes, dtype=\"int64\")\n",
    "print(f\"[INFO] proposal shape: {proposals.shape}\")\n",
    "# classify each of the proposal ROIs using fine-tuned model\n",
    "print(\"[INFO] classifying proposals...\")\n",
    "proba = predict_region_of_interest(model=cnn_model, proposals_used=proposals)  # Predicting the proposals for our desired object\n",
    "                                      # Result: 100 proposals 300 by 300 image with RGB color\n",
    "# Probabilty of each proposal (Region of Proposals)\n",
    "print(f\"[INFO] Probabiltiy Scores: {proba}\")\n",
    "\n",
    "# Obtaining the label of the current prediction from the CNN\n",
    "# Empty list to store proposals\n",
    "proposal_name_list = []\n",
    "for proposals in proba:\n",
    "    \"\"\"\n",
    "    For each predicted proposal\n",
    "    attach the class names and \n",
    "    append it to a list.\n",
    "    \"\"\"\n",
    "    pred_name = classes[np.argmax(proposals)]\n",
    "    proposal_name_list.append(pred_name)\n",
    "# find the index of all predictions that are greater\n",
    "# than the minimum probability\n",
    "print(\"[INFO] applying NMS...\")\n",
    "# Find the indexs where the main prediction label matches the overall image\n",
    "# Get the index of the proposal that has the same class name as the overall image\n",
    "idxs = [i for i, x in enumerate(proposal_name_list) if x == pred_name]\n",
    "boxes = boxes[idxs]\n",
    "proba = proba[idxs]\n",
    "# further filter indexes by enforcing a minimum prediction\n",
    "idxs = np.where(proba >= min_probability)[0]\n",
    "# probability be met\n",
    "boxes = boxes[idxs]\n",
    "proba = proba[idxs]\n",
    "\n",
    "# clone the original image so that we can draw on it\n",
    "clone = image.copy()\n",
    "# loop over the bounding boxes and associated probabilities\n",
    "for (box, prob) in zip(boxes, proba):\n",
    "    # draw the bounding box, label, and probability on the image\n",
    "    (startX, startY, endX, endY) = box\n",
    "    cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "        (0, 255, 0), 2)\n",
    "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    text = f\"{np.round(prob * 100, decimals=3)}%\"\n",
    "    cv2.putText(clone, text, (startX, y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "# show the output after *before* running NMS\n",
    "cv2.imshow(\"Before NMS\", clone)\n",
    "cv2.waitKey(0);\n",
    "\n",
    "# run non-maxima suppression on the bounding boxes\n",
    "boxIdxs = non_max_suppression(boxes=boxes, overlapThresh=0.5)\n",
    "# loop over the bounding box indexes\n",
    "for i in boxIdxs:\n",
    "    # draw the bounding box, label, and probability on the image\n",
    "    (startX, startY, endX, endY) = i # or boxes[0] will return 1 bb\n",
    "    cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "        (0, 255, 0), 2)\n",
    "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "    text = f\"{classes[np.argmax(prob)]}: {np.round(proba.max() * 100, decimals=1)}%\"\n",
    "    cv2.putText(image, text, (startX, y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "# show the output image *after* running NMS\n",
    "cv2.imshow(\"After NMS\", image)\n",
    "cv2.waitKey(0);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
